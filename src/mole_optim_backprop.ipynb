{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTR2wvLhyVPk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import torch\n",
        "from typing_extensions import final\n",
        "import torch.optim as optim\n",
        "import statistics  # For mean and variance calculations\n",
        "import os\n",
        "from numpy import genfromtxt\n",
        "import pickle\n",
        "import random\n",
        "# from matplotlib import pyplot as plt\n",
        "# initialize variables\n",
        "mole_name = \"OHH\"\n",
        "n_orb = 12\n",
        "na_true = 4\n",
        "nb_true = 4\n",
        "# previous code naming N\n",
        "N = n_orb\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LIdiER58ENz",
        "outputId": "fde4f4c0-1a34-43a3-a817-c19f6a8f48bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyscf\n",
            "  Downloading pyscf-2.9.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: numpy!=1.16,!=1.17,>=1.13 in /usr/local/lib/python3.11/dist-packages (from pyscf) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from pyscf) (1.15.3)\n",
            "Requirement already satisfied: h5py>=2.7 in /usr/local/lib/python3.11/dist-packages (from pyscf) (3.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyscf) (75.2.0)\n",
            "Downloading pyscf-2.9.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyscf\n",
            "Successfully installed pyscf-2.9.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install pyscf\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "####Check if running in Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKnAPTi3ZqBY"
      },
      "outputs": [],
      "source": [
        "def scipy_to_torch_sparse(scipy_csr_matrix):\n",
        "    \"\"\"\n",
        "    Convert a SciPy sparse CSR matrix (with float64 data) to a PyTorch sparse CSR tensor (with complex64 data),\n",
        "    minimizing extra memory usage.\n",
        "    Parameters\n",
        "    ----------\n",
        "    scipy_csr_matrix : scipy.sparse.csr_matrix\n",
        "        The input SciPy CSR matrix with float64 data.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    torch.sparse_csr_tensor\n",
        "        The converted PyTorch sparse CSR tensor with complex64 data.\n",
        "    \"\"\"\n",
        "\n",
        "    if not isinstance(scipy_csr_matrix, scipy.sparse.csr_matrix):\n",
        "        raise TypeError(\"Input must be a SciPy CSR matrix.\")\n",
        "\n",
        "    # Extract pointer/indices/data\n",
        "    row_ptr = scipy_csr_matrix.indptr   # shape: (n_rows + 1,)\n",
        "    col_idx = scipy_csr_matrix.indices  # shape: (nnz,)\n",
        "    data = scipy_csr_matrix.data        # shape: (nnz,)\n",
        "    shape = scipy_csr_matrix.shape\n",
        "\n",
        "    # Delete the SciPy object to free overhead memory\n",
        "    del scipy_csr_matrix\n",
        "\n",
        "    # Create PyTorch tensors by sharing memory with NumPy\n",
        "    row_ptr_tensor = torch.from_numpy(row_ptr)\n",
        "    col_idx_tensor = torch.from_numpy(col_idx)\n",
        "    data_tensor = torch.from_numpy(data)\n",
        "\n",
        "    # Delete the NumPy arrays once we have PyTorch references\n",
        "    del row_ptr, col_idx, data\n",
        "\n",
        "    # Ensure row_ptr/col_idx are torch.long (int64)\n",
        "    if row_ptr_tensor.dtype != torch.long:\n",
        "        row_ptr_tensor = row_ptr_tensor.long()\n",
        "    if col_idx_tensor.dtype != torch.long:\n",
        "        col_idx_tensor = col_idx_tensor.long()\n",
        "\n",
        "    # Convert float64 -> complex128 (this is our one unavoidable copy)\n",
        "    data_tensor = data_tensor.to(torch.complex128)\n",
        "\n",
        "    # Create the final sparse CSR tensor\n",
        "    torch_csr_tensor = torch.sparse_csr_tensor(\n",
        "        crow_indices=row_ptr_tensor,\n",
        "        col_indices=col_idx_tensor,\n",
        "        values=data_tensor,\n",
        "        size=shape\n",
        "    )\n",
        "    return torch_csr_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMU_JiflykzH",
        "outputId": "9bb86dc7-4ceb-46e7-80bf-e1c5a51695ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3-2727545122.py:46: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
            "  torch_csr_tensor = torch.sparse_csr_tensor(\n"
          ]
        }
      ],
      "source": [
        "bond_length = 1\n",
        "basis = ['sto-6g','6-31g']\n",
        "basis_choice= 1\n",
        "Mo_AO_basis = ['MO','local_MO']\n",
        "Mo_AO_basis_choice = 1\n",
        "string_name = f'{mole_name}_bond_{bond_length}_Ham_{basis[basis_choice]}_{Mo_AO_basis[Mo_AO_basis_choice]}.npz'\n",
        "string_name_gs = f'{mole_name}_bond_{bond_length}_true_gs_{basis[basis_choice]}_{Mo_AO_basis[Mo_AO_basis_choice]}.csv'\n",
        "\n",
        "if IN_COLAB:\n",
        "    file_path = f'/content/drive/My Drive/Quantum_chemistry/data/Water/states/{string_name}'\n",
        "    file_path_gs = f'/content/drive/My Drive/Quantum_chemistry/data/Water/states/{string_name_gs}'\n",
        "else:\n",
        "    file_path = string_name\n",
        "    file_path_gs = string_name_gs\n",
        "\n",
        "h_sparse = scipy.sparse.load_npz(file_path)\n",
        "h_sparse = scipy_to_torch_sparse(h_sparse)\n",
        "h_sparse = h_sparse.to(device)\n",
        "\n",
        "# Load the eigenvectors\n",
        "true_gs = np.loadtxt(file_path_gs, delimiter=',')\n",
        "\n",
        "# move to gpu\n",
        "true_gs = torch.tensor(true_gs, dtype=torch.complex128).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# true_gs = torch.tensor(true_gs, dtype=torch.float64).to(device)\n",
        "\n",
        "# round_gs = torch.round(true_gs,decimals=5)\n",
        "# round_gs = torch.tensor(round_gs, dtype=torch.complex128).to(device)\n",
        "# calculate_energy(h_sparse,round_gs)"
      ],
      "metadata": {
        "id": "bDheepkdJuM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A1tJzUs8plM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wIaZaIdfpxAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsXHdFFvwaRG"
      },
      "outputs": [],
      "source": [
        "# bond_length = 1\n",
        "# basis = ['sto-6g','6-31g']\n",
        "# basis_choice= 1\n",
        "# Mo_AO_basis = ['MO','local_MO']\n",
        "# Mo_AO_basis_choice = 1\n",
        "# string_name = f'{mole_name}_bond_{bond_length}_Ham_{basis[basis_choice]}_{Mo_AO_basis[Mo_AO_basis_choice]}.npz'\n",
        "# string_name_gs = f'{mole_name}_bond_{bond_length}_true_gs_{basis[basis_choice]}_{Mo_AO_basis[Mo_AO_basis_choice]}.csv'\n",
        "# if IN_COLAB:\n",
        "#     file_path = f'/content/drive/My Drive/Quantum_chemistry/data/Water/states/{string_name}'\n",
        "#     file_path_gs = f'/content/drive/My Drive/Quantum_chemistry/data/Water/states/{string_name_gs}'\n",
        "# else:\n",
        "#     file_path = string_name\n",
        "#     file_path_gs = string_name_gs\n",
        "# true_gs_1 = np.loadtxt(file_path_gs, delimiter=',')\n",
        "# true_gs_1 = torch.tensor(true_gs_1, dtype=torch.complex128).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c8DVm3HxKj4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "726qlzHUwizv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w37fRXz4GE5D"
      },
      "outputs": [],
      "source": [
        "def calculate_energy(input_matrix, psi): # input_matrix is sparse\n",
        "    psi_dagger = torch.conj(psi)  # Conjugate of the state vector\n",
        "    # Sparse matrix-vector multiplication\n",
        "    intermediate = torch.sparse.mm(input_matrix, psi.unsqueeze(1))  # shape (n, 1) # support coo or csr matrix\n",
        "    # Dot product to get the energy\n",
        "    energy = torch.dot(psi_dagger, intermediate.squeeze())  # shape (n,)\n",
        "    return energy.real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_xQLp878AR5",
        "outputId": "6d416dd2-bee0-4285-c389-df31b40b954a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-19.4132131926, device='cuda:0', dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "torch.set_printoptions(precision=10)\n",
        "true_gs_energy = calculate_energy(h_sparse,true_gs)\n",
        "print(true_gs_energy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLmaWqesujeT"
      },
      "outputs": [],
      "source": [
        "# gs energy list for OHH:\n",
        "# r =1, -23.9984226491986\n",
        "# r =1.01, -23.7040\n",
        "# r= 1.25, -22.3022\n",
        "# r= 1.5 , -21.3267\n",
        "# r =1.75,  -20.6262\n",
        "# r =2, -20.1095\n",
        "# r =2.05, -20.0227946472036\n",
        "# r =2.1,-19.940666061819677\n",
        "# r =2.15, -19.8628087583110\n",
        "# r =2.2,  -19.7888961801287\n",
        "# r =2.25, -19.7186\n",
        "# r = 2.5,-19.4132"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiLcoN0X80H3",
        "outputId": "16a5e389-4f23-4896-8f67-b4398f8735db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# start with double occ state, one higher than HF\n",
        "from pyscf.fci import cistring\n",
        "alpha_list = list(cistring.gen_strings4orblist(range(n_orb), na_true))\n",
        "beta_list  = list(cistring.gen_strings4orblist(range(n_orb), nb_true))\n",
        "\n",
        "# Build a list of (alpha, beta) pairs in EXACT the same order as PySCF:\n",
        "basis_pair = []\n",
        "for a in alpha_list:\n",
        "    for b in beta_list:\n",
        "        basis_pair.append((a, b))\n",
        "\n",
        "# Find the second occurrence of a = b\n",
        "matching_indices = [i for i, (a, b) in enumerate(basis_pair) if a == b]\n",
        "\n",
        "state_to_evolve = torch.zeros(h_sparse.shape[0], dtype=torch.complex128)\n",
        "\n",
        "################ line to search initial state\n",
        "# basis_pair.index((np.int64(4368), np.int64(4368)))\n",
        "################\n",
        "state_to_evolve[matching_indices[0]] = 1\n",
        "state_to_evolve = state_to_evolve/torch.norm(state_to_evolve)\n",
        "print(torch.norm(state_to_evolve))\n",
        "# Move to GPU\n",
        "state_to_evolve = state_to_evolve.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ris2Xhh-tWu9"
      },
      "outputs": [],
      "source": [
        "def calculate_fidelity(psi, phi):\n",
        "    \"\"\"\n",
        "    Calculate the fidelity between two state vectors.\n",
        "\n",
        "    Parameters:\n",
        "    psi (torch.Tensor): The first state vector in PyTorch format, dtype=torch.complex128.\n",
        "    phi (torch.Tensor): The second state vector in PyTorch format, dtype=torch.complex128.\n",
        "\n",
        "    Returns:\n",
        "    float: The calculated fidelity.\n",
        "    \"\"\"\n",
        "    fidelity = torch.abs(torch.vdot(psi, phi))**2\n",
        "    return fidelity.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fR_m4Cqlqqp",
        "outputId": "cf78c3a1-1148-48cc-e512-a5efb77041c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.646817425047819e-07\n"
          ]
        }
      ],
      "source": [
        "print(calculate_fidelity(state_to_evolve,true_gs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdwo9xMOyq9T",
        "outputId": "ab4896d7-5a00-402a-bc84-4818fe5f61a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-13.1049177341, device='cuda:0', dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# # check the energy of the state to evolve\n",
        "print(calculate_energy(h_sparse,state_to_evolve))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3wIFKd3C7Aj"
      },
      "outputs": [],
      "source": [
        "# U part, read data\n",
        "string_name = f'number_op_list_norb={N}_na_{na_true}_nb_{nb_true}.txt'\n",
        "if IN_COLAB:\n",
        "    file_path = f'/content/drive/My Drive/Quantum_chemistry/hardware_effient/{string_name}'\n",
        "else:\n",
        "    file_path = string_name\n",
        "\n",
        "number_op_list = torch.tensor(np.loadtxt(file_path))\n",
        "# move to gpu\n",
        "number_op_list = number_op_list.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmU7WadEJ9mN"
      },
      "outputs": [],
      "source": [
        "def UCC_U_part_torch(input_state, para_index, input_theta):\n",
        "    \"\"\"\n",
        "    Apply the UCC U part operation on the input state.\n",
        "\n",
        "    Parameters:\n",
        "    input_state (torch.Tensor): The input state tensor in PyTorch format, dtype=torch.complex128.\n",
        "    para_index (int): The index to select the corresponding number operator from number_op_list.\n",
        "    input_theta (float): The input theta parameter for the phase factor.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: The output state after applying the phase factors.\n",
        "    \"\"\"\n",
        "    occ_list = number_op_list[para_index]\n",
        "\n",
        "    # Compute the phase factors\n",
        "    phase_factor_list = torch.exp(1j * input_theta * occ_list)\n",
        "\n",
        "    # Apply the phase factors to the input state\n",
        "    output_state = phase_factor_list * input_state\n",
        "\n",
        "    return output_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCzFXjis1Jx4"
      },
      "outputs": [],
      "source": [
        "# UCC_U_part_torch(state_to_evolve,2,torch.tensor([0.3],dtype=torch.float64).to(device ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9hAwE61KGqZ"
      },
      "outputs": [],
      "source": [
        "# Specify the file path to save the dictionary\n",
        "string_name = f'torch_hopping_cose_dict_norb={N}_na_{na_true}_nb_{nb_true}.pkl'\n",
        "\n",
        "# Load the dictionary from the file\n",
        "if IN_COLAB:\n",
        "    file_path = f'/content/drive/My Drive/Quantum_chemistry/hardware_effient/{string_name}'\n",
        "else:\n",
        "    file_path = string_name\n",
        "\n",
        "hopping_cose_dict = pickle.load(open(file_path, 'rb'))\n",
        "\n",
        "# Convert numpy arrays to torch tensors\n",
        "hopping_cose_dict = {key: torch.tensor(value, device=device) for key, value in hopping_cose_dict.items()}\n",
        "###############################################################################################################################################################\n",
        "\n",
        "string_name = f'torch_sparse_matrices_dict_norb={N}_na_{na_true}_nb_{nb_true}.pkl'\n",
        "if IN_COLAB:\n",
        "    file_path = f'/content/drive/My Drive/Quantum_chemistry/hardware_effient/{string_name}'\n",
        "else:\n",
        "    file_path = string_name\n",
        "\n",
        "# Load the dictionary from the file\n",
        "sparse_matrices_dict = pickle.load(open(file_path, 'rb'))\n",
        "\n",
        "# Convert SciPy sparse COO matrices to PyTorch sparse COO tensors\n",
        "sparse_matrices_dict = {key: scipy_to_torch_sparse(value) for key, value in sparse_matrices_dict.items()}\n",
        "# Move PyTorch sparse COO tensors to GPU\n",
        "sparse_matrices_dict = {key: value.to(device) for key, value in sparse_matrices_dict.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1svlUSyX47PQ"
      },
      "outputs": [],
      "source": [
        "# In this case, it turns out we only use hopping only\n",
        "for hopping_pair in sparse_matrices_dict:\n",
        "    original_csr = sparse_matrices_dict[hopping_pair]\n",
        "\n",
        "    # Transpose and convert back to CSR\n",
        "    transposed_csr = original_csr.transpose(0, 1).to_sparse_csr()\n",
        "\n",
        "    # Add the original and transposed matrices\n",
        "    updated_csr = original_csr + transposed_csr\n",
        "\n",
        "    # Replace the original matrix with the updated one\n",
        "    sparse_matrices_dict[hopping_pair] = updated_csr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQ8rcYX68AR7"
      },
      "outputs": [],
      "source": [
        "##############################################################################\n",
        "# 1) T-type operator (no chunking)\n",
        "##############################################################################\n",
        "def UCC_t_part_torch(psi, site_pair, theta):\n",
        "    \"\"\"\n",
        "    T-type excitation:\n",
        "        |psi> -> cos(theta)*|psi> + i*sin(theta)*(hop_matrix @ |psi>)\n",
        "    applied for spin=+1 and spin=-1.\n",
        "    \"\"\"\n",
        "    out = psi\n",
        "    for spin in [1, -1]:\n",
        "        key = site_pair + (spin,)\n",
        "        # cos(...) mask\n",
        "        cos_mask = torch.ones_like(out)\n",
        "        idx = hopping_cose_dict[key]  # 1D index array\n",
        "        cos_mask[idx] = torch.cos(theta).to(torch.complex128)\n",
        "        part1 = cos_mask * out\n",
        "\n",
        "        # hopping part\n",
        "        hop_mat = sparse_matrices_dict[key]  # NxN sparse\n",
        "        spmv = torch.sparse.mm(hop_mat, out.unsqueeze(1)).squeeze(1)\n",
        "        part2 = (1j * torch.sin(theta).to(torch.complex128)) * spmv\n",
        "\n",
        "        out = part1 + part2\n",
        "    return out\n",
        "\n",
        "##############################################################################\n",
        "# 2) U-type operator (no chunking)\n",
        "##############################################################################\n",
        "def UCC_U_part_torch(psi, number_idx, theta):\n",
        "    \"\"\"\n",
        "    U-type excitation:\n",
        "       |psi> -> e^{ i * theta * n } |psi>\n",
        "    where n = number_op_list[number_idx].\n",
        "    \"\"\"\n",
        "    occ = number_op_list[number_idx]  # shape (N,) real\n",
        "    phase = torch.exp(1j * theta * occ.to(torch.complex128))\n",
        "    return psi * phase\n",
        "\n",
        "##############################################################################\n",
        "# 3) Apply all excitations in a single pass\n",
        "##############################################################################\n",
        "def apply_all_excitations(psi, x):\n",
        "    \"\"\"\n",
        "    Applies every excitation in para_value_list (in order) to the wavefunction psi.\n",
        "    Each entry in para_value_list is either:\n",
        "      (u_index, param_idx) for U-type\n",
        "      (siteA, siteB, param_idx) for T-type\n",
        "    \"\"\"\n",
        "    out = psi\n",
        "    for exc in para_value_list:\n",
        "        if len(exc) == 2:\n",
        "            # U-type\n",
        "            out = UCC_U_part_torch(out, exc[0], x[exc[1]])\n",
        "        else:\n",
        "            # T-type\n",
        "            out = UCC_t_part_torch(out, (exc[0], exc[1]), x[exc[2]])\n",
        "    return out\n",
        "\n",
        "##############################################################################\n",
        "# 4) Classical optimizer: direct forward pass + energy\n",
        "##############################################################################\n",
        "def classical_optimizer(x):\n",
        "    \"\"\"\n",
        "    1) Clone the global 'state_to_evolve'\n",
        "    2) Apply all excitations once (no chunking/checkpointing)\n",
        "    3) Compute energy with calculate_energy(h_sparse, final_psi)\n",
        "    \"\"\"\n",
        "    psi_init = state_to_evolve.clone()\n",
        "    psi_final = apply_all_excitations(psi_init, x)\n",
        "    return calculate_energy(h_sparse, psi_final)\n",
        "\n",
        "def fidelity_classical_optimizer(x):\n",
        "    \"\"\"\n",
        "    1) Clone the global 'state_to_evolve'\n",
        "    2) Apply all excitations once (no chunking/checkpointing)\n",
        "    3) Compute energy with calculate_energy(h_sparse, final_psi)\n",
        "    \"\"\"\n",
        "    psi_init = state_to_evolve.clone()\n",
        "    psi_final = apply_all_excitations(psi_init, x)\n",
        "    return calculate_fidelity(true_gs, psi_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7HFiCB_PEgU"
      },
      "outputs": [],
      "source": [
        "nn_condition = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCVjZavTO1rJ"
      },
      "outputs": [],
      "source": [
        "u_index =[]\n",
        "t_index =[]\n",
        "def generate_parameters(para_repeat_times):\n",
        "    global counting_parameter_index\n",
        "    para_value_list = []\n",
        "    counting_parameter_index = 0\n",
        "\n",
        "    def can_commute(term, group):\n",
        "        j, k, _ = term\n",
        "        term_sites = {j, k}\n",
        "        for existing_term in group:\n",
        "            ej, ek, _ = existing_term\n",
        "            existing_sites = {ej, ek}\n",
        "            if term_sites & existing_sites:  # non-empty overlap => they don't commute\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    # -------------------------------------------------------------\n",
        "    # Main loop over para_repeat_times\n",
        "    # -------------------------------------------------------------\n",
        "    for iteration in range(para_repeat_times):\n",
        "        # ---------------------------------------------------------\n",
        "        # 1) Collect all hopping terms\n",
        "        # ---------------------------------------------------------\n",
        "        hopping_terms = []\n",
        "        for j in range(N):\n",
        "            for k in range(N):\n",
        "                if nn_condition:\n",
        "                    if j == k+1:\n",
        "                        t_index.append(counting_parameter_index)\n",
        "                        hopping_terms.append((j, k, counting_parameter_index))\n",
        "                        counting_parameter_index += 1\n",
        "                else:\n",
        "                    if k < j:\n",
        "                        t_index.append(counting_parameter_index)\n",
        "                        hopping_terms.append((j, k, counting_parameter_index))\n",
        "                        counting_parameter_index += 1\n",
        "        # ---------------------------------------------------------\n",
        "        # 2) Collect U-terms\n",
        "        # ---------------------------------------------------------\n",
        "        U_terms = []\n",
        "        for i in range(N):\n",
        "            u_index.append(counting_parameter_index)\n",
        "            U_terms.append((i, counting_parameter_index))\n",
        "            counting_parameter_index += 1\n",
        "\n",
        "        # ---------------------------------------------------------\n",
        "        # 3) Separate into NN vs. non-NN\n",
        "        # ---------------------------------------------------------\n",
        "        nn_terms = []\n",
        "        non_nn_terms = []\n",
        "        for t in hopping_terms:\n",
        "            j, k, _ = t\n",
        "            if j == k + 1:\n",
        "                nn_terms.append(t)\n",
        "            else:\n",
        "                non_nn_terms.append(t)\n",
        "\n",
        "        # ---------------------------------------------------------\n",
        "        # 4) Build Group 1: (1,0) + commuting NN\n",
        "        # ---------------------------------------------------------\n",
        "        group1 = []\n",
        "        leftover_nn_1 = []\n",
        "\n",
        "        g1_special = None\n",
        "        for t in nn_terms:\n",
        "            if t[:2] == (1, 0):\n",
        "                g1_special = t\n",
        "                break\n",
        "\n",
        "        if g1_special is not None:\n",
        "            group1.append(g1_special)\n",
        "\n",
        "        for t in nn_terms:\n",
        "            if t == g1_special:\n",
        "                continue\n",
        "            if group1 and can_commute(t, group1):\n",
        "                group1.append(t)\n",
        "            else:\n",
        "                leftover_nn_1.append(t)\n",
        "\n",
        "        # ---------------------------------------------------------\n",
        "        # 5) Build Group 2: (2,1) + commuting NN\n",
        "        # ---------------------------------------------------------\n",
        "        group2 = []\n",
        "        leftover_nn_2 = []\n",
        "\n",
        "        g2_special = None\n",
        "        for t in leftover_nn_1:\n",
        "            if t[:2] == (2, 1):\n",
        "                g2_special = t\n",
        "                break\n",
        "\n",
        "        if g2_special is not None:\n",
        "            group2.append(g2_special)\n",
        "\n",
        "        for t in leftover_nn_1:\n",
        "            if t == g2_special:\n",
        "                continue\n",
        "            if group2 and can_commute(t, group2):\n",
        "                group2.append(t)\n",
        "            else:\n",
        "                leftover_nn_2.append(t)\n",
        "\n",
        "        # leftover_nn_2 now has leftover NN terms\n",
        "        # non_nn_terms are all non-NN from above\n",
        "        leftover_terms = leftover_nn_2 + non_nn_terms\n",
        "\n",
        "        # ---------------------------------------------------------\n",
        "        # 6) Group leftover terms (normal commuting logic)\n",
        "        # ---------------------------------------------------------\n",
        "        leftover_commuting_groups = []\n",
        "        for t in leftover_terms:\n",
        "            placed = False\n",
        "            for g in leftover_commuting_groups:\n",
        "                if can_commute(t, g):\n",
        "                    g.append(t)\n",
        "                    placed = True\n",
        "                    break\n",
        "            if not placed:\n",
        "                leftover_commuting_groups.append([t])\n",
        "\n",
        "        # ---------------------------------------------------------\n",
        "        # 7) Combine all groups, then shuffle them\n",
        "        # ---------------------------------------------------------\n",
        "        commuting_groups = []\n",
        "        if group1:\n",
        "            commuting_groups.append(group1)\n",
        "        if group2:\n",
        "            commuting_groups.append(group2)\n",
        "        commuting_groups.extend(leftover_commuting_groups)\n",
        "\n",
        "        # # Shuffle all groups for this iteration\n",
        "        # random.shuffle(commuting_groups)\n",
        "\n",
        "        # ---------------------------------------------------------\n",
        "        # 8) Flatten them and append U-terms\n",
        "        # ---------------------------------------------------------\n",
        "        ordered_hopping_list = [term for group in commuting_groups for term in group]\n",
        "        para_value_list.extend(ordered_hopping_list)\n",
        "        para_value_list.extend(U_terms)\n",
        "\n",
        "        #####(Optional) Print for debugging\n",
        "        # print(f\"\\nIteration {iteration} / {para_repeat_times}, commuting groups (randomly ordered):\")\n",
        "        # for idx, group in enumerate(commuting_groups):\n",
        "        #     print(f\"  Group {idx+1}: {group}\")\n",
        "\n",
        "    return para_value_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo-kNaST8AR8",
        "outputId": "d616e5d4-68b7-4e83-e57a-ac9e66a36a2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "920\n"
          ]
        }
      ],
      "source": [
        "para_repeat_times=40\n",
        "para_value_list = generate_parameters(para_repeat_times)\n",
        "print(len(para_value_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJBTDIPtScYT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBKzC1CKbs7a",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "984cb93e-baad-4066-fff9-8306bdf697dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-19.3743047250, device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# input value to check energy\n",
        "x = np.load('predicted_limit_epsilon.npy')\n",
        "x = torch.tensor(x, dtype=torch.float64, device=device, requires_grad=False)\n",
        "classical_optimizer(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-19.3648826728 , n=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph1lyDU-uiuH",
        "outputId": "20f8bdd0-82c8-4ba8-c77c-5df0cfc6cd9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-19.4132131926, device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dxHzHV6euirx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lH_wLx4OPEgV",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    filename = f'/content/drive/My Drive/Quantum_chemistry/result/log_{mole_name}_bond_{bond_length}_para_{para_repeat_times}.txt'\n",
        "    checkpoint_filename = f'/content/drive/My Drive/Quantum_chemistry/result/checkpoint_{mole_name}_bond_{bond_length}_para_{para_repeat_times}.pt'\n",
        "else:\n",
        "    filename = f'log_{mole_name}_bond_{bond_length}_para_{para_repeat_times}.txt'\n",
        "    checkpoint_filename = f'checkpoint_{mole_name}_bond_{bond_length}_para_{para_repeat_times}.pt'\n",
        "lr = 0.1\n",
        "energy_threshold = 1e-8 # Stopping condition for cost function change\n",
        "gradient_norm_threshold =1e-4\n",
        "max_epochs = 5000\n",
        "write_file_condition = True\n",
        "# Initialize x if checkpoint does not exist\n",
        "if os.path.isfile(checkpoint_filename):\n",
        "    checkpoint = torch.load(checkpoint_filename,weights_only=False)\n",
        "    x = torch.tensor(checkpoint['x'], dtype=torch.float64, device=device, requires_grad=True)\n",
        "    # Initialize L-BFGS optimizer\n",
        "    optimizer = optim.LBFGS([x], lr=lr)\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "else:\n",
        "    initial_guess = np.pi/3*np.ones( counting_parameter_index)\n",
        "    #initial_guess = np.random.uniform(0,2*3.14159, counting_parameter_index)\n",
        "    # initial_guess = np.zeros(counting_parameter_index)\n",
        "    # initial_guess[t_index] = np.ones(len(t_index))*(-np.pi/64)\n",
        "    # initial_guess[t_index] = np.random.uniform(-np.pi/128,np.pi/128, len(t_index))\n",
        "    x = torch.tensor(initial_guess, dtype=torch.float64, device=device, requires_grad=True)\n",
        "    optimizer = optim.LBFGS([x], lr=lr, max_iter=20, history_size=100,line_search_fn='strong_wolfe')\n",
        "    epoch = 0\n",
        "prev_energy = None  # Store previous energy for stopping condition\n",
        "def closure():\n",
        "    optimizer.zero_grad()\n",
        "    energy = classical_optimizer(x)\n",
        "    energy.backward()\n",
        "    return energy\n",
        "with open(filename, 'a') as f:  # Use 'a' to append to the log file if it exists\n",
        "    while epoch < max_epochs:\n",
        "        optimizer.step(closure)\n",
        "        # Compute gradient norm\n",
        "        gradient_norm = x.grad.norm().cpu().detach().numpy()\n",
        "        # Compute current energy\n",
        "        current_energy = classical_optimizer(x).cpu().detach().numpy()\n",
        "        # Compute energy difference if previous energy exists\n",
        "        energy_diff = abs(current_energy - prev_energy) if prev_energy is not None else float('inf')\n",
        "        prev_energy = current_energy  # Update previous energy\n",
        "        result_str = f\"Epoch {epoch + 1}, Energy: {current_energy:.6f}, Gradient Norm: {gradient_norm:.6f}, Energy Diff: {energy_diff:.8f}\\n\"\n",
        "        print(result_str, end='')\n",
        "        if write_file_condition:\n",
        "            # Log and save data\n",
        "            if (epoch + 1) % 1 == 0:\n",
        "                f.write(result_str)\n",
        "                # Append latest x values to the end of the file\n",
        "                x_values = ','.join([str(val.item()) for val in x.detach().cpu().numpy()])\n",
        "                f.write(f\"Latest x values at epoch {epoch + 1}: {x_values}\\n\")\n",
        "                # Save checkpoint\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'x': x.detach().cpu().numpy(),  # Save as numpy array for checkpoint\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                }, checkpoint_filename)\n",
        "\n",
        "        # **Stopping condition: both gradient norm and energy difference must be small**\n",
        "        if  energy_diff < energy_threshold or gradient_norm < gradient_norm_threshold :\n",
        "            print(f\"Stopping at epoch {epoch + 1} due to small energy difference.\")\n",
        "            break\n",
        "        epoch += 1\n",
        "        f.flush()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QWekLeilINv"
      },
      "outputs": [],
      "source": [
        "fidelity_classical_optimizer(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uHpdgGO5Zq5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-3osjI18AR8"
      },
      "outputs": [],
      "source": [
        "# # test spin\n",
        "# # Load the sparse matrix in pytorch COO format with complex 128 data\n",
        "# total_S = scipy.sparse.load_npz('total_S_norb=10_na_7_nb_7.npz').tocoo()\n",
        "# total_S = scipy_to_torch_sparse(total_S)\n",
        "# total_S = total_S.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZj0xOU21xRa"
      },
      "outputs": [],
      "source": [
        "filename = f'final_report_{mole_name}_bond_{bond_length}_para_{para_repeat_times}.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQglzVD61xIS"
      },
      "outputs": [],
      "source": [
        "# once done write result file\n",
        "\n",
        "#outcome result\n",
        "length = len(para_value_list)\n",
        "\n",
        "# Determine if tensor 'x' is on GPU or CPU\n",
        "if x.is_cuda:\n",
        "    # GPU version\n",
        "    final_energy_diff = (classical_optimizer(x).detach().cpu() - true_gs_energy).cpu().numpy()\n",
        "else:\n",
        "\n",
        "    # CPU version\n",
        "    final_energy_diff = (classical_optimizer(x).detach() - true_gs_energy).numpy()\n",
        "\n",
        "######################################################################\n",
        "\n",
        "final_fidelity = fidelity_classical_optimizer(x)\n",
        "x_values = ','.join([str(val.item()) for val in x.detach().cpu().numpy()])\n",
        "# Write results to file\n",
        "with open(filename, 'w') as file:\n",
        "    file.write(f\"Final Energy Diff: {final_energy_diff}\\n\")\n",
        "    file.write(f\"Final Fidelity: {final_fidelity}\\n\")\n",
        "    file.write(f\"Optimized X Values: {x_values}\\n\")\n",
        "    file.write(f\"Length of parameter value list: {length}\\n\")\n",
        "    file.write(f\"Epoch : {epoch }\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpPXm7sDlINv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}